{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef59011",
   "metadata": {},
   "source": [
    "# poetryのインストール・仮想環境のアクティベート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # モデルのインポート\n",
    "import os\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc1baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo : CasualLM と CasualLLM の違いを調べる\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94641138",
   "metadata": {},
   "source": [
    "# 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_remote_code = True\n",
    "# hugging face cli tokenの設定\n",
    "os.environ[\"HUGGINGFACE_TOKEN\"] = \"\"\n",
    "output_dir = \"./output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacd7523",
   "metadata": {},
   "source": [
    "# 量子化読み込みの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e08211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8bit量子化を行う\n",
    "load_in_8bit = True\n",
    "load_in_4bit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=load_in_8bit, load_in_4bit=load_in_4bit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d32b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUを使う\n",
    "device_map = {\"\": 0}\n",
    "# bfloat16を使う\n",
    "torch_dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8069cdd3",
   "metadata": {},
   "source": [
    "# モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b859b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hugging faceのモデルを指定\n",
    "# use llama2\n",
    "base_model = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=device_map,\n",
    "    torch_dtype=torch_dtype,\n",
    "    use_auth_token=trust_remote_code,\n",
    "    trust_remote_code=trust_remote_code,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizerの設定\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "# paddingのトークンはeosとは別にしないといけない\n",
    "# llama2はeosがpaddingのトークンになっている...どうすれば？？\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94296ae",
   "metadata": {},
   "source": [
    "# 基本の学習パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6dc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "gradient_accumulation_steps = 1\n",
    "learining_rate = 5e-5\n",
    "num_train_epochs = 1\n",
    "logging_steps = 100\n",
    "max_steps = -1\n",
    "save_steps = 100\n",
    "save_total_limit = 10\n",
    "val_size = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=learining_rate,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    logging_steps=logging_steps,\n",
    "    max_steps=max_steps,\n",
    "    save_steps=save_steps,\n",
    "    save_total_limit=save_total_limit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140defec",
   "metadata": {},
   "source": [
    "# PEFTの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5342d7",
   "metadata": {},
   "source": [
    "## Lora\n",
    " \n",
    "loraの設定 with peft library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_r: int = 8\n",
    "lora_alpha: int = 16\n",
    "lora_dropout: float = 0.05\n",
    "lora_target_modules: list[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c8c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = peft.LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    target_modules=lora_target_modules,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CASUAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b548c",
   "metadata": {},
   "source": [
    "## AdaLoraの設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775eb41",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# loraの設定\n",
    "lora_r: int = 8\n",
    "lora_alpha: int = 16\n",
    "lora_dropout: float = 0.05\n",
    "lora_target_modules: list[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc463c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapter特有の設定\n",
    "target_r: int = 8\n",
    "init_r: int = 12\n",
    "tinit_r: int = 0\n",
    "tfinal_r: int = 0\n",
    "deltaT: float = 1.0\n",
    "beta1: float = 0.85\n",
    "beta2: float = 0.85\n",
    "orth_reg_weight: float = 0.0\n",
    "total_step: list[int] = None\n",
    "rank_patterns: list[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adalora_config = peft.AdaLoraConfig(\n",
    "        # lora setting\n",
    "        lora_r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=lora_target_modules,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CASUAL_LM\"\n",
    "        # adalora setting\n",
    "        target_r=target_r,\n",
    "        init_r=init_r,\n",
    "        tinit_r=tinit_r,\n",
    "        tfinal_r=tfinal_r,\n",
    "        deltaT=deltaT,\n",
    "        beta1=beta1,\n",
    "        beta2=beta2,\n",
    "        orth_reg_weight=orth_reg_weight,\n",
    "        total_step=total_step,\n",
    "        rank_patterns=rank_patterns,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae525b",
   "metadata": {},
   "source": [
    "## Prefix-tuningの設定\n",
    "https://huggingface.co/docs/peft/task_guides/ptuning-seq-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ddb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_virtual_tokens: int = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ff546",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_config = peft.PrefixTuningConfig(\n",
    "    num_virtual_tokens=num_virtual_tokens, task_type=\"CASUAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e302b7c0",
   "metadata": {},
   "source": [
    "# Prompt-tuningの設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ccb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : 設定調べる\n",
    "# これはhugging faceにあったデフォルトの設定\n",
    "prompt_tuning_init: str = peft.PromptTuningInit.Text  # or \"random\"\n",
    "prompt_tuning_init_text: str = \"\"  # prompttuningのテキストを指定\n",
    "num_virtual_tokens: int = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_config = peft.PromptTuningConfig(\n",
    "    prompt_tuning_init=prompt_tuning_init,\n",
    "    prompt_tuning_init_text=prompt_tuning_init_text,\n",
    "    num_virtual_tokens=num_virtual_tokens,\n",
    "    task_type=\"CASUAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a40c0b3",
   "metadata": {},
   "source": [
    "## P-tuningの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-tuningではprompt encoderで設定を行う\n",
    "num_virtual_tokens: int = 8  # 仮想トークンの数\n",
    "encoder_hidden_dim: int = 128  # prompt encoderの隠れ層の次元数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b420ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_config = peft.PromptEncoderConfig(\n",
    "    num_virtual_tokens=num_virtual_tokens,\n",
    "    encoder_hidden_dim=encoder_hidden_dim,\n",
    "    task_type=\"CASUAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2289f3",
   "metadata": {},
   "source": [
    "## IA3の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全然わからない\n",
    "# TODO : 設定調べる\n",
    "target_modules: list[str] = (None,)\n",
    "feedforward_modules: list[str] = (None,)\n",
    "fan_in_fan_out = true\n",
    "modules_to_save: list[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc3fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia3_config = peft.IA3Config(\n",
    "        target_modules=None,\n",
    "        feedforward_modules=\n",
    "        fan_in_fan_out = fan_in_fan_out,\n",
    "        modules_to_save=None\n",
    "        task_type=\"CASUAL_LM\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3092075c",
   "metadata": {},
   "source": [
    "## Adapter H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0615e",
   "metadata": {},
   "source": [
    "## Adapter P "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6cfd8",
   "metadata": {},
   "source": [
    "## Adapter Pararell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac0049",
   "metadata": {},
   "source": [
    "# peftモデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5536096",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff028d1e",
   "metadata": {},
   "source": [
    "# データセットの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f4ef8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def formatting_func(examples: list[dict]):\n",
    "    \"\"\"データセットのフォーマットを設定する関数\n",
    "\n",
    "    Args :\n",
    "        examples (list[dict]): データセットのdict\n",
    "    Returns\n",
    "        (list[str]): フォーマットされたデータセット\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "\n",
    "    for example in examples:\n",
    "        if example[\"input\"]:\n",
    "            text = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \n",
    "\n",
    "                ### Instruction:\n",
    "                {example[\"instruction\"]}\n",
    "                \n",
    "                ### Input:\n",
    "                {example[\"input\"]}\n",
    "                \n",
    "                ### Response:\n",
    "                {example[\"output\"]}\"\"\"\n",
    "            texts.append(text)\n",
    "        else:\n",
    "            text = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
    "\n",
    "                ### Instruction:\n",
    "                {example[\"instruction\"]}\n",
    "                \n",
    "                ### Response:\n",
    "                {example[\"output\"]}\"\"\"\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8a708",
   "metadata": {},
   "source": [
    "## データセットの読み込み\n",
    "データセットはjson形式で保存されている必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"\"\n",
    "dataset = load_dataset(\"json\", data_files=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainとtestに分ける\n",
    "train_val = dataset.train_test_split(test_size=val_size, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_val[\"train\"].shuffle().map(formatting_func)\n",
    "val_data = train_val[\"test\"].shuffle().map(formatting_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        args = training_args,\n",
    "        data_collator = DataCollatorForSeq2Seq(tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\" padding=True)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2-fine-tuning-wuKDcxYi-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
